# train_model/main.py
"""
é«˜é€Ÿå…¬è·¯æ™ºèƒ½äº¤é€šç³»çµ±ä¸»æœå‹™å™¨
æ•´åˆ RAG èŠå¤©å’Œäº¤é€šç®¡ç†è€…é¡§å•åŠŸèƒ½
æ”¯æ´è‡ªå‹•æª¢æ¸¬ä¸¦åŸ·è¡Œè¨“ç·´æµç¨‹
"""

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
import uvicorn
import asyncio
from datetime import datetime
from contextlib import asynccontextmanager
import sys
from pathlib import Path

# å°å…¥æœ¬åœ°æ¨¡çµ„
from models.controller_advisor import router as controller_router
from models.ollama_client import OllamaClient, RAGOllamaChat
from embeddings.vector_store import VectorStore, RAGRetriever

# å°å…¥ API æ¨¡å‹
from pydantic import BaseModel
from typing import Optional, List

# =============================================================================
# API æ¨¡å‹å®šç¾©
# =============================================================================

class SimpleChatRequest(BaseModel):
    """ç°¡å–®èŠå¤©è«‹æ±‚"""
    message: str
    session_id: Optional[str] = None
    include_sources: bool = True

class SimpleChatResponse(BaseModel):
    """ç°¡å–®èŠå¤©å›æ‡‰"""
    response: str
    sources: Optional[List[str]] = []
    confidence: Optional[float] = 0.0
    session_id: str
    processing_time: Optional[float] = None

# =============================================================================
# å…¨åŸŸè®Šæ•¸
# =============================================================================

rag_chat_system = None

# =============================================================================
# è‡ªå‹•è¨“ç·´å‡½æ•¸
# =============================================================================

async def auto_setup_rag_system():
    """è‡ªå‹•è¨­ç½® RAG ç³»çµ±ï¼Œå¦‚éœ€è¦å‰‡åŸ·è¡Œè¨“ç·´"""
    global rag_chat_system
    
    print("ğŸ” æª¢æŸ¥ RAG ç³»çµ±ç‹€æ…‹...")
    
    try:
        # æª¢æŸ¥å‘é‡è³‡æ–™åº«
        vector_store = VectorStore()
        stats = vector_store.get_collection_stats()
        document_count = stats.get('document_count', 0)
        
        print(f"ğŸ“Š ç•¶å‰å‘é‡è³‡æ–™åº«æ–‡æª”æ•¸é‡: {document_count}")
        
        # å¦‚æœæ–‡æª”æ•¸é‡å°‘æ–¼ 10ï¼ŒåŸ·è¡Œè‡ªå‹•è¨“ç·´
        if document_count < 10:
            print("âš ï¸ å‘é‡è³‡æ–™åº«ç‚ºç©ºæˆ–æ–‡æª”éå°‘ï¼Œé–‹å§‹è‡ªå‹•è¨“ç·´...")
            await auto_train_rag_system()
            
            # é‡æ–°æª¢æŸ¥
            stats = vector_store.get_collection_stats()
            document_count = stats.get('document_count', 0)
            print(f"ğŸ“Š è¨“ç·´å¾Œæ–‡æª”æ•¸é‡: {document_count}")
        
        # åˆå§‹åŒ– Ollama å®¢æˆ¶ç«¯
        ollama_client = OllamaClient()
        
        # æª¢æŸ¥ Ollama é€£æ¥
        print("ğŸ”— æª¢æŸ¥ Ollama æœå‹™é€£æ¥...")
        ollama_connected = await ollama_client.check_connection()
        
        if not ollama_connected:
            print("âŒ Ollama æœå‹™æœªé€£æ¥")
            print("è«‹åŸ·è¡Œä»¥ä¸‹å‘½ä»¤å•Ÿå‹• Ollama:")
            print("1. ollama serve")
            print("2. ollama pull llama3.1:8b")
            return None
        
        print("âœ… Ollama æœå‹™é€£æ¥æˆåŠŸ")
        
        # åˆå§‹åŒ– RAG èŠå¤©ç³»çµ±
        retriever = RAGRetriever(vector_store)
        rag_chat_system = RAGOllamaChat(ollama_client, retriever)
        
        print("âœ… RAG èŠå¤©ç³»çµ±åˆå§‹åŒ–å®Œæˆ")
        return rag_chat_system
        
    except Exception as e:
        print(f"âŒ RAG ç³»çµ±è¨­ç½®å¤±æ•—: {e}")
        return None

async def auto_train_rag_system():
    """è‡ªå‹•åŸ·è¡Œ RAG ç³»çµ±è¨“ç·´"""
    print("ğŸš€ é–‹å§‹è‡ªå‹•è¨“ç·´ RAG ç³»çµ±...")
    
    try:
        # å‹•æ…‹å°å…¥è¨“ç·´æ¨¡çµ„ï¼ˆé¿å…å¾ªç’°å°å…¥ï¼‰
        from scripts.train_rag import RAGTrainer
        
        # å‰µå»ºè¨“ç·´å™¨
        trainer = RAGTrainer()
        
        print("ğŸ“š è¨­ç½®è¨“ç·´çµ„ä»¶...")
        await trainer.setup_components()
        
        print("ğŸ”„ è™•ç†è¨“ç·´è³‡æ–™...")
        processed_data_path = trainer.process_data(force_reprocess=False)
        
        print("ğŸ—ï¸ å»ºç«‹å‘é‡ç´¢å¼•...")
        trainer.build_vector_index(processed_data_path, force_rebuild=False)
        
        print("âœ… è‡ªå‹•è¨“ç·´å®Œæˆ")
        
    except ImportError as e:
        print(f"âŒ ç„¡æ³•å°å…¥è¨“ç·´æ¨¡çµ„: {e}")
        print("è«‹ç¢ºä¿ train_rag.py æª”æ¡ˆå­˜åœ¨")
        raise
    except Exception as e:
        print(f"âŒ è‡ªå‹•è¨“ç·´å¤±æ•—: {e}")
        raise

# =============================================================================
# æ‡‰ç”¨ç”Ÿå‘½é€±æœŸç®¡ç†
# =============================================================================

@asynccontextmanager
async def lifespan(app: FastAPI):
    """æ‡‰ç”¨ç”Ÿå‘½é€±æœŸç®¡ç†"""
    global rag_chat_system
    
    print("ğŸš€ å•Ÿå‹•é«˜é€Ÿå…¬è·¯æ™ºèƒ½äº¤é€šç³»çµ±...")
    print("=" * 60)
    
    # è‡ªå‹•è¨­ç½® RAG ç³»çµ±
    rag_chat_system = await auto_setup_rag_system()
    
    if rag_chat_system:
        print("ğŸ¤– äº¤é€šç®¡ç†è€…é¡§å•ç³»çµ±å·²æº–å‚™å°±ç·’")
    else:
        print("âš ï¸ RAG èŠå¤©ç³»çµ±æœªæˆåŠŸåˆå§‹åŒ–ï¼Œéƒ¨åˆ†åŠŸèƒ½å°‡å—é™")
    
    print("=" * 60)
    print("ğŸŒ æœå‹™ç«¯é»:")
    print("   â€¢ ç°¡å–®èŠå¤©: POST /api/chat")
    print("   â€¢ ç®¡ç†è€…é¡§å•: POST /api/controller/chat")
    print("   â€¢ ç³»çµ±ç‹€æ…‹: GET /api/status")
    print("   â€¢ æ‰‹å‹•è¨“ç·´: POST /api/admin/retrain")
    print("   â€¢ API æ–‡æª”: http://localhost:8000/docs")
    print("=" * 60)
    
    yield
    
    print("â¹ï¸ é—œé–‰é«˜é€Ÿå…¬è·¯æ™ºèƒ½äº¤é€šç³»çµ±...")

# =============================================================================
# FastAPI æ‡‰ç”¨è¨­ç½®
# =============================================================================

app = FastAPI(
    title="Highway Intelligent Traffic System",
    description="é«˜é€Ÿå…¬è·¯æ™ºèƒ½äº¤é€šç³»çµ± - åŒ…å« RAG èŠå¤©å’Œäº¤é€šç®¡ç†è€…é¡§å•",
    version="2.1.0",
    lifespan=lifespan
)

# CORS è¨­ç½®
app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "http://localhost:3000",     # React é–‹ç™¼æœå‹™å™¨
        "http://127.0.0.1:3000",    # æ›¿ä»£æœ¬åœ°åœ°å€
        "http://localhost:3001",    # å‚™ç”¨ç«¯å£
    ],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# =============================================================================
# è·¯ç”±è¨»å†Š
# =============================================================================

# åŒ…å«äº¤é€šç®¡ç†è€…é¡§å•è·¯ç”±
app.include_router(controller_router, prefix="/api", tags=["Controller Advisor"])

# =============================================================================
# ç°¡å–® RAG èŠå¤©ç«¯é»
# =============================================================================

@app.post("/api/chat", response_model=SimpleChatResponse)
async def simple_chat(request: SimpleChatRequest):
    """ç°¡å–®çš„ RAG èŠå¤©ç«¯é»"""
    start_time = datetime.now()
    
    try:
        if not rag_chat_system:
            raise HTTPException(
                status_code=503, 
                detail="RAG èŠå¤©ç³»çµ±æœªåˆå§‹åŒ–ï¼Œè«‹æª¢æŸ¥ Ollama æœå‹™æˆ–åŸ·è¡Œæ‰‹å‹•è¨“ç·´"
            )
        
        # ç”Ÿæˆå›æ‡‰
        response = await rag_chat_system.chat(request.message)
        
        # æª¢ç´¢ç›¸é—œæ–‡æª”ä½œç‚ºä¾†æº
        vector_store = VectorStore()
        search_results = vector_store.search(request.message, top_k=3)
        sources = [result['text'][:200] + '...' for result in search_results]
        
        # è¨ˆç®—ä¿¡å¿ƒåº¦
        confidence = sum(result['score'] for result in search_results) / len(search_results) if search_results else 0.0
        
        # è¨ˆç®—è™•ç†æ™‚é–“
        processing_time = (datetime.now() - start_time).total_seconds() * 1000
        
        return SimpleChatResponse(
            response=response,
            sources=sources if request.include_sources else [],
            confidence=min(confidence, 1.0),
            session_id=request.session_id or f"chat-{int(datetime.now().timestamp())}",
            processing_time=processing_time
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"èŠå¤©è™•ç†å¤±æ•—: {str(e)}")

# =============================================================================
# ç®¡ç†ç«¯é»
# =============================================================================

@app.post("/api/admin/retrain")
async def manual_retrain():
    """æ‰‹å‹•é‡æ–°è¨“ç·´ RAG ç³»çµ±"""
    global rag_chat_system
    
    try:
        print("ğŸ”„ é–‹å§‹æ‰‹å‹•é‡æ–°è¨“ç·´...")
        
        # åŸ·è¡Œè¨“ç·´
        await auto_train_rag_system()
        
        # é‡æ–°åˆå§‹åŒ–èŠå¤©ç³»çµ±
        rag_chat_system = await auto_setup_rag_system()
        
        return {
            "status": "success",
            "message": "RAG ç³»çµ±é‡æ–°è¨“ç·´å®Œæˆ",
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"é‡æ–°è¨“ç·´å¤±æ•—: {str(e)}")

@app.get("/api/admin/training-status")
async def get_training_status():
    """ç²å–è¨“ç·´ç‹€æ…‹"""
    try:
        vector_store = VectorStore()
        stats = vector_store.get_collection_stats()
        
        return {
            "document_count": stats.get('document_count', 0),
            "is_trained": stats.get('document_count', 0) > 0,
            "rag_system_ready": rag_chat_system is not None,
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        return {
            "document_count": 0,
            "is_trained": False,
            "rag_system_ready": False,
            "error": str(e),
            "timestamp": datetime.now().isoformat()
        }

# =============================================================================
# ç³»çµ±ç‹€æ…‹å’Œè³‡è¨Šç«¯é»
# =============================================================================

@app.get("/")
async def root():
    """æ ¹ç«¯é» - ç³»çµ±è³‡è¨Š"""
    return {
        "name": "Highway Intelligent Traffic System",
        "version": "2.1.0",
        "description": "é«˜é€Ÿå…¬è·¯æ™ºèƒ½äº¤é€šç³»çµ± - æ”¯æ´è‡ªå‹•è¨“ç·´",
        "status": "operational",
        "auto_training": "enabled",
        "timestamp": datetime.now().isoformat(),
        "endpoints": {
            "simple_chat": {
                "url": "/api/chat",
                "method": "POST",
                "description": "ç°¡å–®çš„ RAG èŠå¤©åŠŸèƒ½"
            },
            "controller_chat": {
                "url": "/api/controller/chat", 
                "method": "POST",
                "description": "äº¤é€šç®¡ç†è€…å°ˆç”¨é¡§å•"
            },
            "manual_retrain": {
                "url": "/api/admin/retrain",
                "method": "POST",
                "description": "æ‰‹å‹•é‡æ–°è¨“ç·´ç³»çµ±"
            },
            "training_status": {
                "url": "/api/admin/training-status",
                "method": "GET",
                "description": "æŸ¥çœ‹è¨“ç·´ç‹€æ…‹"
            }
        }
    }

@app.get("/api/status")
async def get_system_status():
    """ç²å–æ•´é«”ç³»çµ±ç‹€æ…‹"""
    try:
        # æª¢æŸ¥ RAG ç³»çµ±
        rag_status = "operational" if rag_chat_system else "unavailable"
        
        # æª¢æŸ¥å‘é‡è³‡æ–™åº«
        try:
            vector_store = VectorStore()
            vector_stats = vector_store.get_collection_stats()
            vector_status = "operational" if vector_stats.get('document_count', 0) > 0 else "empty"
        except Exception:
            vector_stats = {"document_count": 0}
            vector_status = "error"
        
        # æª¢æŸ¥ Ollama
        try:
            ollama_client = OllamaClient()
            ollama_status = "operational" if await ollama_client.check_connection() else "unavailable"
        except Exception:
            ollama_status = "error"
        
        return {
            "system": {
                "status": "operational",
                "timestamp": datetime.now().isoformat(),
                "auto_training": "enabled"
            },
            "services": {
                "rag_chat": {
                    "status": rag_status,
                    "endpoint": "/api/chat"
                },
                "controller_advisor": {
                    "status": "operational",
                    "endpoint": "/api/controller/chat"
                },
                "vector_database": {
                    "status": vector_status,
                    "document_count": vector_stats.get("document_count", 0)
                },
                "ollama_service": {
                    "status": ollama_status,
                    "description": "Large Language Model Service"
                }
            },
            "health_check": {
                "overall": "healthy" if all([
                    rag_status != "error",
                    vector_status != "error", 
                    ollama_status != "error"
                ]) else "degraded"
            }
        }
        
    except Exception as e:
        return JSONResponse(
            status_code=500,
            content={
                "system": {"status": "error", "error": str(e)},
                "timestamp": datetime.now().isoformat()
            }
        )

@app.get("/health")
async def health_check():
    """ç°¡å–®çš„å¥åº·æª¢æŸ¥"""
    return {
        "status": "healthy",
        "service": "Highway Intelligent Traffic System",
        "auto_training": "enabled",
        "timestamp": datetime.now().isoformat()
    }

# =============================================================================
# ä¸»å‡½æ•¸
# =============================================================================

def main():
    """ä¸»å‡½æ•¸ - å•Ÿå‹•æœå‹™å™¨"""
    print("ğŸš€ å•Ÿå‹•é«˜é€Ÿå…¬è·¯æ™ºèƒ½äº¤é€šç³»çµ±æœå‹™å™¨...")
    print("ğŸ“ æœå‹™å™¨å°‡åœ¨ http://localhost:8000 å•Ÿå‹•")
    print("ğŸ“– API æ–‡æª”å¯åœ¨ http://localhost:8000/docs æŸ¥çœ‹")
    print("ğŸ¤– æ”¯æ´è‡ªå‹•è¨“ç·´å’Œæ‰‹å‹•é‡è¨“åŠŸèƒ½")
    
    uvicorn.run(
        "main:app",
        host="0.0.0.0",
        port=8000,
        reload=True,
        log_level="info",
        reload_dirs=["./"]  # ç›£æ§ç•¶å‰ç›®éŒ„è®ŠåŒ–
    )

if __name__ == "__main__":
    main()