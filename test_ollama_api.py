#!/usr/bin/env python3
import requests
import json

def test_ollama_direct():
    """æ¸¬è©¦ç›´æ¥èª¿ç”¨ Ollama"""
    print("ğŸ”§ æ¸¬è©¦ç›´æ¥èª¿ç”¨ Ollama...")
    
    url = "http://localhost:11434/api/generate"
    payload = {
        "model": "qwen2.5:7b",
        "prompt": "ä½ å¥½ï¼Œè«‹åˆ†æç•¶å‰äº¤é€šç‹€æ³ä¸¦æä¾›å»ºè­°ã€‚",
        "stream": False,
        "options": {
            "temperature": 0.7,
            "num_predict": 200
        }
    }
    
    try:
        response = requests.post(url, json=payload, timeout=30)
        if response.ok:
            result = response.json()
            print("âœ… Ollama ç›´æ¥èª¿ç”¨æˆåŠŸ!")
            print(f"å›æ‡‰: {result.get('response', 'ç„¡å›æ‡‰')[:100]}...")
            return True
        else:
            print(f"âŒ Ollama èª¿ç”¨å¤±æ•—: {response.status_code}")
            return False
    except Exception as e:
        print(f"âŒ Ollama é€£æ¥éŒ¯èª¤: {e}")
        return False

def test_traffic_api():
    """æ¸¬è©¦äº¤é€šæ•¸æ“š API"""
    print("\nğŸš— æ¸¬è©¦äº¤é€šæ•¸æ“š API...")
    
    try:
        response = requests.get("http://localhost:8000/api/traffic/current", timeout=10)
        if response.ok:
            data = response.json()
            print(f"âœ… äº¤é€šæ•¸æ“šç²å–æˆåŠŸ! ç«™é»æ•¸: {len(data.get('stations', []))}")
            return data
        else:
            print(f"âŒ äº¤é€šæ•¸æ“šç²å–å¤±æ•—: {response.status_code}")
            return None
    except Exception as e:
        print(f"âŒ äº¤é€šæ•¸æ“š API éŒ¯èª¤: {e}")
        return None

def test_integrated_chat():
    """æ¸¬è©¦æ•´åˆçš„èŠå¤©åŠŸèƒ½"""
    print("\nğŸ¤– æ¸¬è©¦æ•´åˆèŠå¤©åŠŸèƒ½...")
    
    # ç²å–äº¤é€šæ•¸æ“š
    traffic_data = test_traffic_api()
    
    # æ¨¡æ“¬äº¤é€šæ•¸æ“šåˆ†æè«‹æ±‚
    url = "http://localhost:11434/api/generate"
    
    # æ§‹å»ºåŒ…å«äº¤é€šæ•¸æ“šçš„æç¤º
    if traffic_data:
        stations = traffic_data.get('stations', [])
        total_stations = len(stations)
        avg_speed = sum(s.get('speed', 0) for s in stations) / total_stations if total_stations > 0 else 0
        
        traffic_summary = f"""
ç•¶å‰äº¤é€šç‹€æ³ï¼š
- ç›£æ¸¬ç«™é»: {total_stations} å€‹
- å¹³å‡è»Šé€Ÿ: {avg_speed:.1f} km/h
- æ›´æ–°æ™‚é–“: {traffic_data.get('last_updated', 'æœªçŸ¥')}
"""
        
        prompt = f"""ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„äº¤é€šåˆ†æåŠ©æ‰‹ï¼Œè«‹æ ¹æ“šä»¥ä¸‹å³æ™‚äº¤é€šæ•¸æ“šæä¾›é§•é§›å»ºè­°ï¼š

{traffic_summary}

ç”¨æˆ¶å•é¡Œï¼šç›®å‰è·¯æ³å¦‚ä½•ï¼Ÿæœ‰ä»€éº¼é§•é§›å»ºè­°ï¼Ÿ

è«‹ç”¨ç¹é«”ä¸­æ–‡å›ç­”ï¼Œæä¾›å…·é«”ä¸”å¯¦ç”¨çš„å»ºè­°ã€‚"""
    else:
        prompt = "ä½ æ˜¯äº¤é€šåŠ©æ‰‹ï¼Œç›®å‰æ²’æœ‰å³æ™‚æ•¸æ“šï¼Œè«‹æä¾›ä¸€èˆ¬æ€§çš„é§•é§›å®‰å…¨å»ºè­°ã€‚"
    
    payload = {
        "model": "qwen2.5:7b",
        "prompt": prompt,
        "stream": False,
        "options": {
            "temperature": 0.7,
            "num_predict": 300
        }
    }
    
    try:
        response = requests.post(url, json=payload, timeout=30)
        if response.ok:
            result = response.json()
            print("âœ… æ•´åˆèŠå¤©æ¸¬è©¦æˆåŠŸ!")
            print("ğŸ¤– AI å›æ‡‰:")
            print(result.get('response', 'ç„¡å›æ‡‰'))
            return True
        else:
            print(f"âŒ æ•´åˆèŠå¤©å¤±æ•—: {response.status_code}")
            return False
    except Exception as e:
        print(f"âŒ æ•´åˆèŠå¤©éŒ¯èª¤: {e}")
        return False

if __name__ == "__main__":
    print("ğŸš€ é–‹å§‹æ¸¬è©¦ Ollama æ•´åˆåŠŸèƒ½...\n")
    
    # æ¸¬è©¦å„å€‹çµ„ä»¶
    ollama_ok = test_ollama_direct()
    traffic_ok = test_traffic_api() is not None
    chat_ok = test_integrated_chat()
    
    print(f"\nğŸ“Š æ¸¬è©¦çµæœç¸½çµ:")
    print(f"- Ollama æœå‹™: {'âœ…' if ollama_ok else 'âŒ'}")
    print(f"- äº¤é€šæ•¸æ“š API: {'âœ…' if traffic_ok else 'âŒ'}")
    print(f"- æ•´åˆèŠå¤©åŠŸèƒ½: {'âœ…' if chat_ok else 'âŒ'}")
    
    if ollama_ok and traffic_ok and chat_ok:
        print("\nğŸ‰ æ‰€æœ‰æ¸¬è©¦é€šéï¼å¯ä»¥é–‹å§‹æ•´åˆå‰ç«¯ã€‚")
    else:
        print("\nâš ï¸ éƒ¨åˆ†æ¸¬è©¦å¤±æ•—ï¼Œéœ€è¦ä¿®å¾©å¾Œå†ç¹¼çºŒã€‚")