"""
å¢å¼·çš„ CSV è³‡æ–™è™•ç†å™¨
è§£æ±ºä»£è™Ÿæª¢ç´¢å•é¡Œï¼Œæ·»åŠ é§•é§›å‹å–„çš„è·¯æ®µæè¿°
"""

import pandas as pd
import numpy as np
import os
import json
from typing import List, Dict, Any, Tuple
from loguru import logger
import jieba

# å°å…¥é…ç½®ç®¡ç†å™¨å’ŒåŸå§‹è™•ç†å™¨
import sys
from pathlib import Path
sys.path.append(str(Path(__file__).parent.parent))
from train_model.utils.config_manager import get_config_manager
from train_model.data_processing.csv_processor import HighwayCSVProcessor

class EnhancedHighwayCSVProcessor(HighwayCSVProcessor):
    """å¢å¼·çš„åœ‹é“CSVè³‡æ–™è™•ç†å™¨ - æ”¯æ´é§•é§›å‹å–„æè¿°"""
    
    def __init__(self, config_path: str = None):
        """åˆå§‹åŒ–å¢å¼·è™•ç†å™¨"""
        super().__init__(config_path)
        
        # è¼‰å…¥ç«™é»æ˜ å°„è³‡æ–™
        self.etag_data = self._load_etag_mapping()
        self.station_mapping = self._build_station_mapping()
        
        # è¼‰å…¥ä¼‘æ¯ç«™å’Œäº¤æµé“è³‡è¨Š
        self.rest_areas = self._load_rest_areas()
        self.interchange_info = self._load_interchange_info()
        
        logger.info("å¢å¼·CSVè™•ç†å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def _load_etag_mapping(self) -> pd.DataFrame:
        """è¼‰å…¥ Etag ç«™é»æ˜ å°„è³‡æ–™"""
        try:
            base_path = self.config_manager.resolve_path(self.data_config['input_data_path'])
            etag_file = os.path.join(base_path, '../Taiwan/Etag.csv')
            
            if os.path.exists(etag_file):
                etag_df = pd.read_csv(etag_file, encoding='utf-8')
                logger.info(f"è¼‰å…¥ Etag æ˜ å°„è³‡æ–™: {len(etag_df)} ç­†è¨˜éŒ„")
                return etag_df
            else:
                logger.warning(f"Etag æª”æ¡ˆä¸å­˜åœ¨: {etag_file}")
                return pd.DataFrame()
                
        except Exception as e:
            logger.error(f"è¼‰å…¥ Etag æ˜ å°„è³‡æ–™å¤±æ•—: {e}")
            return pd.DataFrame()
    
    def _build_station_mapping(self) -> Dict[str, Dict[str, Any]]:
        """å»ºç«‹ç«™é»ä»£è™Ÿåˆ°å‹å–„åç¨±çš„æ˜ å°„ï¼ˆä½¿ç”¨å°ˆæ¡ˆç¾æœ‰é‚è¼¯ï¼‰"""
        station_mapping = {}
        
        if self.etag_data.empty:
            return station_mapping
        
        for _, row in self.etag_data.iterrows():
            try:
                # æå–ç«™é»ç·¨è™Ÿï¼ˆå»é™¤ç‰ˆæœ¬è™Ÿï¼‰- ä½¿ç”¨èˆ‡ propagation_system.py ç›¸åŒé‚è¼¯
                station_code = row['ç·¨è™Ÿ']
                if pd.isna(station_code):
                    continue
                    
                # å°‡ç«™é»ç·¨è™Ÿè½‰æ›ç‚ºè³‡æ–™ä¸­çš„æ ¼å¼
                # ä¾‹å¦‚ï¼š01F-034.0N -> 01F0340N
                clean_code = station_code.replace('-', '').replace('.', '')
                
                # å»ºç«‹æ˜ å°„ï¼ˆä½¿ç”¨å°ˆæ¡ˆç¾æœ‰çµæ§‹ï¼‰
                station_mapping[clean_code] = {
                    'id': row['ID'],
                    'direction': row['æ–¹å‘'], 
                    'original_code': station_code,
                    'start_ic': row['äº¤æµé“(èµ·)'],
                    'end_ic': row['äº¤æµé“(è¿„)'],
                    'friendly_name': f"{row['äº¤æµé“(èµ·)']} è‡³ {row['äº¤æµé“(è¿„)']}",
                    'highway': station_code[:3] if len(station_code) >= 3 else "",
                    'mileage': self._extract_mileage(station_code),
                    'latitude': row['ç·¯åº¦(åŒ—ç·¯)'] if pd.notna(row['ç·¯åº¦(åŒ—ç·¯)']) else None,
                    'longitude': row['ç¶“åº¦(æ±ç¶“)'] if pd.notna(row['ç¶“åº¦(æ±ç¶“)']) else None
                }
                
            except Exception as e:
                logger.warning(f"è™•ç†ç«™é»æ˜ å°„å¤±æ•— {row.get('ç·¨è™Ÿ', 'Unknown')}: {e}")
                continue
        
        logger.info(f"å»ºç«‹ç«™é»æ˜ å°„: {len(station_mapping)} å€‹ç«™é»")
        return station_mapping
    
    def _extract_mileage(self, station_code: str) -> float:
        """å¾ç«™é»ç·¨è™Ÿä¸­æå–é‡Œç¨‹æ•¸"""
        try:
            # 01F-034.0N -> 34.0
            if '-' in station_code and '.' in station_code:
                parts = station_code.split('-')[1]  # 034.0N
                mileage_str = parts.replace('N', '').replace('S', '')  # 034.0
                return float(mileage_str)
            return 0.0
        except:
            return 0.0
    
    def _load_rest_areas(self) -> Dict[str, List[Dict[str, Any]]]:
        """è¼‰å…¥ä¼‘æ¯ç«™è³‡è¨Š"""
        # åœ‹é“ä¼‘æ¯ç«™è³‡è¨Šï¼ˆå¯ä»¥å¾å¤–éƒ¨æª”æ¡ˆè¼‰å…¥ï¼‰
        rest_areas = {
            '01F': [  # åœ‹é“ä¸€è™Ÿ
                {'name': 'ä¸­å£¢æœå‹™å€', 'mileage': 53.2, 'direction': 'both', 'facilities': ['åŠ æ²¹ç«™', 'é¤å»³', 'ä¾¿åˆ©åº—', 'åœè»Šå ´']},
                {'name': 'æ¹–å£æœå‹™å€', 'mileage': 62.5, 'direction': 'both', 'facilities': ['åŠ æ²¹ç«™', 'é¤å»³', 'ä¾¿åˆ©åº—', 'åœè»Šå ´']},
                {'name': 'è¥¿èºæœå‹™å€', 'mileage': 232.0, 'direction': 'both', 'facilities': ['åŠ æ²¹ç«™', 'é¤å»³', 'ä¾¿åˆ©åº—', 'åœè»Šå ´']},
                {'name': 'æ³°å®‰æœå‹™å€', 'mileage': 264.5, 'direction': 'both', 'facilities': ['åŠ æ²¹ç«™', 'é¤å»³', 'ä¾¿åˆ©åº—', 'åœè»Šå ´', 'ä¼‘æ¯å€']},
            ],
            '03F': [  # åœ‹é“ä¸‰è™Ÿ
                {'name': 'é—œè¥¿æœå‹™å€', 'mileage': 79.0, 'direction': 'both', 'facilities': ['åŠ æ²¹ç«™', 'é¤å»³', 'ä¾¿åˆ©åº—', 'åœè»Šå ´']},
                {'name': 'è¥¿æ¹–æœå‹™å€', 'mileage': 132.5, 'direction': 'both', 'facilities': ['åŠ æ²¹ç«™', 'é¤å»³', 'ä¾¿åˆ©åº—', 'åœè»Šå ´']},
                {'name': 'å—æŠ•æœå‹™å€', 'mileage': 214.0, 'direction': 'both', 'facilities': ['åŠ æ²¹ç«™', 'é¤å»³', 'ä¾¿åˆ©åº—', 'åœè»Šå ´']},
                {'name': 'å¤å‘æœå‹™å€', 'mileage': 254.5, 'direction': 'both', 'facilities': ['åŠ æ²¹ç«™', 'é¤å»³', 'ä¾¿åˆ©åº—', 'åœè»Šå ´']},
            ]
        }
        
        logger.info(f"è¼‰å…¥ä¼‘æ¯ç«™è³‡è¨Š: åœ‹é“1è™Ÿ {len(rest_areas['01F'])} å€‹ï¼Œåœ‹é“3è™Ÿ {len(rest_areas['03F'])} å€‹")
        return rest_areas
    
    def _load_interchange_info(self) -> Dict[str, Dict[str, Any]]:
        """è¼‰å…¥äº¤æµé“æ›¿ä»£è·¯ç·šè³‡è¨Š"""
        # ä¸»è¦äº¤æµé“çš„æ›¿ä»£è·¯ç·šè³‡è¨Š
        interchange_info = {
            # åŒ—éƒ¨åœ°å€
            'äº”è‚¡': {
                'alternatives': ['å°64ç·š', 'å°1ç·š', 'å°15ç·š'],
                'description': 'å¯ä½¿ç”¨å°64ç·šå¿«é€Ÿé“è·¯æˆ–å°1ç·šçœé“ä½œç‚ºæ›¿ä»£é“è·¯',
                'peak_hours': ['07:00-09:00', '17:00-19:00']
            },
            'æ—å£': {
                'alternatives': ['å°61ç·š', 'å°1ç·š'],
                'description': 'å¯ç¶“ç”±å°61ç·šè¥¿æ¿±å¿«é€Ÿé“è·¯ç¹è¡Œ',
                'peak_hours': ['07:30-09:30', '17:30-19:30']
            },
            'æ¡ƒåœ’': {
                'alternatives': ['å°4ç·š', 'å°1ç·š', 'ç¸£é“113ç·š'],
                'description': 'å¯ä½¿ç”¨å°4ç·šæˆ–ç¸£é“113ç·šé€²å…¥æ¡ƒåœ’å¸‚å€',
                'peak_hours': ['07:00-09:00', '17:00-19:00']
            },
            'ä¸­å£¢': {
                'alternatives': ['å°1ç·š', 'ç¸£é“114ç·š', 'å°66ç·š'],
                'description': 'å¯ä½¿ç”¨å°66ç·šæ±è¥¿å‘å¿«é€Ÿé“è·¯æˆ–å°1ç·š',
                'peak_hours': ['07:30-09:30', '17:30-19:30']
            },
            
            # ä¸­éƒ¨åœ°å€
            'å°ä¸­': {
                'alternatives': ['å°74ç·š', 'å°1ç·š', 'å°3ç·š'],
                'description': 'å¯ä½¿ç”¨å°74ç·šå¿«é€Ÿé“è·¯æˆ–å°1ç·šçœé“',
                'peak_hours': ['07:00-09:00', '17:00-19:00']
            },
            'å½°åŒ–': {
                'alternatives': ['å°1ç·š', 'å°19ç·š', 'ç¸£é“139ç·š'],
                'description': 'å¯ç¶“ç”±å°1ç·šæˆ–å°19ç·šç¹è¡Œå½°åŒ–å¸‚å€',
                'peak_hours': ['07:30-09:30', '17:30-19:30']
            },
            
            # å—éƒ¨åœ°å€
            'å°å—': {
                'alternatives': ['å°86ç·š', 'å°1ç·š', 'å°17ç·š'],
                'description': 'å¯ä½¿ç”¨å°86ç·šå¿«é€Ÿé“è·¯æˆ–å°17ç·šæ¿±æµ·å…¬è·¯',
                'peak_hours': ['07:00-09:00', '17:00-19:00']
            },
            'é«˜é›„': {
                'alternatives': ['å°88ç·š', 'å°1ç·š', 'å°17ç·š'],
                'description': 'å¯ä½¿ç”¨å°88ç·šå¿«é€Ÿé“è·¯é€²å…¥é«˜é›„',
                'peak_hours': ['07:30-09:30', '17:30-19:30']
            }
        }
        
        logger.info(f"è¼‰å…¥äº¤æµé“æ›¿ä»£è·¯ç·šè³‡è¨Š: {len(interchange_info)} å€‹äº¤æµé“")
        return interchange_info
    
    def resolve_station_code(self, station_code: str) -> str:
        """è§£æç«™é»ä»£è™Ÿç‚ºå‹å–„åç¨±ï¼ˆä½¿ç”¨å°ˆæ¡ˆç¾æœ‰é‚è¼¯ï¼‰"""
        
        # é¦–å…ˆå˜—è©¦å¾ CSV æ ¼å¼è§£æï¼šN0010_SB,034K+000
        if ',' in station_code and 'K+' in station_code:
            try:
                parts = station_code.split(',')
                direction_code = parts[0].strip()
                mileage_code = parts[1].strip()
                
                # è§£æåœ‹é“å’Œæ–¹å‘
                if 'N0010' in direction_code:
                    highway = 'åœ‹é“1è™Ÿ'
                    direction = 'åŒ—å‘' if 'NB' in direction_code else 'å—å‘'
                    highway_code = '01F'
                elif 'N0030' in direction_code:
                    highway = 'åœ‹é“3è™Ÿ' 
                    direction = 'åŒ—å‘' if 'NB' in direction_code else 'å—å‘'
                    highway_code = '03F'
                else:
                    return station_code  # ç„¡æ³•è­˜åˆ¥çš„æ ¼å¼
                
                # è§£æé‡Œç¨‹
                if 'K+' in mileage_code:
                    km_str = mileage_code.split('K+')[0]
                    km = float(km_str)
                    
                    # æ§‹å»ºå°æ‡‰çš„ Etag æ ¼å¼é€²è¡ŒæŸ¥æ‰¾
                    # ä¾‹å¦‚ï¼š034K+000 -> 01F-034.0N
                    etag_format = f"{highway_code}-{km_str:0>3}.0{'N' if 'åŒ—å‘' in direction else 'S'}"
                    clean_etag = etag_format.replace('-', '').replace('.', '')
                    
                    # å˜—è©¦å¾æ˜ å°„ä¸­æŸ¥æ‰¾
                    if clean_etag in self.station_mapping:
                        mapping = self.station_mapping[clean_etag]
                        return mapping['friendly_name']
                    
                    # å¦‚æœæ²’æ‰¾åˆ°æ˜ å°„ï¼Œè¿”å›åŸºæœ¬æè¿°
                    return f"{highway}{direction} {km}å…¬é‡Œè™•"
                    
            except Exception as e:
                logger.warning(f"è§£æCSVæ ¼å¼ä»£è™Ÿå¤±æ•— {station_code}: {e}")
        
        # å˜—è©¦ç›´æ¥å¾ Etag æ ¼å¼æ˜ å°„æŸ¥æ‰¾
        if station_code in self.station_mapping:
            return self.station_mapping[station_code]['friendly_name']
        
        # å˜—è©¦æ¸…ç†æ ¼å¼å¾ŒæŸ¥æ‰¾
        clean_code = station_code.replace('-', '').replace('.', '').replace('_', '')
        if clean_code in self.station_mapping:
            return self.station_mapping[clean_code]['friendly_name']
        
        return station_code  # å¦‚æœç„¡æ³•è§£æï¼Œè¿”å›åŸä»£è™Ÿ
    
    def find_nearby_rest_areas(self, highway: str, mileage: float, direction: str = 'both') -> List[Dict[str, Any]]:
        """å°‹æ‰¾é™„è¿‘çš„ä¼‘æ¯ç«™"""
        if highway not in self.rest_areas:
            return []
        
        nearby_areas = []
        for area in self.rest_areas[highway]:
            distance = abs(area['mileage'] - mileage)
            
            # åªè€ƒæ…®50å…¬é‡Œå…§çš„ä¼‘æ¯ç«™
            if distance <= 50:
                area_info = area.copy()
                area_info['distance_km'] = distance
                area_info['is_ahead'] = area['mileage'] > mileage
                nearby_areas.append(area_info)
        
        # æŒ‰è·é›¢æ’åº
        nearby_areas.sort(key=lambda x: x['distance_km'])
        return nearby_areas
    
    def get_alternative_routes(self, start_ic: str, end_ic: str) -> List[str]:
        """ç²å–æ›¿ä»£è·¯ç·šå»ºè­°"""
        alternatives = []
        
        # æª¢æŸ¥èµ·é»äº¤æµé“çš„æ›¿ä»£è·¯ç·š
        for ic_name, info in self.interchange_info.items():
            if ic_name in start_ic or ic_name in end_ic:
                alternatives.extend(info['alternatives'])
        
        # å»é‡ä¸¦è¿”å›
        return list(set(alternatives))
    
    def generate_enhanced_text_descriptions(self, df: pd.DataFrame) -> List[str]:
        """ç”Ÿæˆå¢å¼·çš„æ–‡å­—æè¿° - åŒ…å«å‹å–„åç¨±å’Œé§•é§›å»ºè­°"""
        descriptions = []
        
        for idx, row in df.iterrows():
            try:
                # è§£æåŸºæœ¬è³‡è¨Š
                direction_code = str(row['åœ‹é“ç·¨è™Ÿæ–¹å‘'])
                mileage_str = str(row['æ¨è™Ÿ'])
                mileage_num = float(row['é‡Œç¨‹']) / 1000  # è½‰æ›ç‚ºå…¬é‡Œ
                
                # è§£æåœ‹é“å’Œæ–¹å‘
                if 'N0010' in direction_code:
                    highway = 'åœ‹é“1è™Ÿ'
                    highway_code = '01F'
                    direction = 'åŒ—å‘' if 'NB' in direction_code else 'å—å‘'
                elif 'N0030' in direction_code:
                    highway = 'åœ‹é“3è™Ÿ'
                    highway_code = '03F'
                    direction = 'åŒ—å‘' if 'NB' in direction_code else 'å—å‘'
                else:
                    highway = 'åœ‹é“'
                    highway_code = '01F'
                    direction = ''
                
                # åŸºæœ¬è·¯æ®µæè¿°
                desc = f"""=== {highway}{direction} {mileage_num:.1f}å…¬é‡Œè™•è·¯æ®µè³‡è¨Š ===

ğŸ“ ä½ç½®è³‡è¨Šï¼š
â€¢ åœ‹é“ï¼š{highway}
â€¢ æ–¹å‘ï¼š{direction}
â€¢ é‡Œç¨‹ï¼š{mileage_num:.1f}å…¬é‡Œ ({mileage_str})
â€¢ èª¿æŸ¥æ—¥æœŸï¼š{row['èª¿æŸ¥æ—¥æœŸ']}
â€¢ åº§æ¨™ï¼šåŒ—ç·¯ {row['ç¶“ç·¯åº¦åæ¨™Lat']:.6f}ï¼Œæ±ç¶“ {row['ç¶“ç·¯åº¦åæ¨™Lon']:.6f}

ğŸ›£ï¸ é“è·¯è¦æ ¼ï¼š
â€¢ é‹ªé¢é¡å‹ï¼š{row['é‹ªé¢ç¨®é¡']}
â€¢ è·¯å¹…å¯¬åº¦ï¼š{row['è·¯å¹…å¯¬']}å…¬å°ºï¼ˆå…¨è·¯å¹…ï¼š{row['å…¨è·¯å¹…å¯¬']}å…¬å°ºï¼‰
â€¢ ä¸»ç·šè»Šé“æ•¸ï¼š{int(row['è»Šé“æ•¸'])}è»Šé“"""

                # è»Šé“å¯¬åº¦è©³ç´°è³‡è¨Š
                lane_info = []
                for i in range(1, 7):
                    lane_width = row.get(f'è»Šé“{i}å¯¬', 0)
                    if pd.notna(lane_width) and float(lane_width) > 0:
                        lane_info.append(f"ç¬¬{i}è»Šé“ {lane_width}å…¬å°º")
                
                if lane_info:
                    desc += f"\nâ€¢ è»Šé“å¯¬åº¦ï¼š{' | '.join(lane_info)}"
                
                # è·¯è‚©è³‡è¨Š
                shoulder_info = []
                if row.get('å…§è·¯è‚©') == 'æœ‰' and pd.notna(row.get('å…§è·¯è‚©å¯¬')) and float(row.get('å…§è·¯è‚©å¯¬', 0)) > 0:
                    shoulder_info.append(f"å…§è·¯è‚© {row['å…§è·¯è‚©å¯¬']}å…¬å°º")
                if row.get('å¤–è·¯è‚©') == 'ç„¡' and pd.notna(row.get('å¤–è·¯è‚©å¯¬')) and float(row.get('å¤–è·¯è‚©å¯¬', 0)) > 0:
                    shoulder_info.append(f"å¤–è·¯è‚© {row['å¤–è·¯è‚©å¯¬']}å…¬å°º")
                
                if shoulder_info:
                    desc += f"\nâ€¢ è·¯è‚©è¨­æ–½ï¼š{' | '.join(shoulder_info)}"
                
                # è¼”åŠ©è»Šé“è³‡è¨Š
                aux_lanes = []
                for i in range(1, 4):
                    aux_lane = row.get(f'è¼”åŠ©è»Šé“{i}')
                    aux_width = row.get(f'è¼”åŠ©è»Šé“{i}å¯¬', 0)
                    if pd.notna(aux_lane) and aux_lane != 'ç„¡' and pd.notna(aux_width) and float(aux_width) > 0:
                        aux_lanes.append(f"è¼”åŠ©è»Šé“{i} {aux_width}å…¬å°º")
                
                if aux_lanes:
                    desc += f"\nâ€¢ è¼”åŠ©è»Šé“ï¼š{' | '.join(aux_lanes)}"
                
                # å¹¾ä½•è¨­è¨ˆç‰¹æ€§
                desc += f"\n\nğŸ”„ å¹¾ä½•è¨­è¨ˆï¼š"
                if pd.notna(row.get('æ›²ç‡åŠå¾‘')) and float(row.get('æ›²ç‡åŠå¾‘', 0)) > 0:
                    curvature = float(row['æ›²ç‡åŠå¾‘'])
                    if curvature < 500:
                        curve_desc = "æ€¥å½è·¯æ®µ"
                    elif curvature < 1000:
                        curve_desc = "å½é“è·¯æ®µ"
                    else:
                        curve_desc = "ç·©å½è·¯æ®µ"
                    desc += f"\nâ€¢ æ›²ç‡åŠå¾‘ï¼š{curvature}å…¬å°º ({curve_desc})"
                
                if pd.notna(row.get('ç¸±å‘å¡åº¦')):
                    slope = float(row['ç¸±å‘å¡åº¦'])
                    if abs(slope) > 0.03:
                        slope_desc = "é™¡å¡è·¯æ®µ" if abs(slope) > 0.05 else "ç·©å¡è·¯æ®µ"
                    else:
                        slope_desc = "å¹³å¦è·¯æ®µ"
                    desc += f"\nâ€¢ ç¸±å‘å¡åº¦ï¼š{slope:.3f} ({slope_desc})"
                
                if pd.notna(row.get('æ©«å‘å¡åº¦')):
                    desc += f"\nâ€¢ æ©«å‘å¡åº¦ï¼š{float(row['æ©«å‘å¡åº¦']):.3f}"
                
                # å°‹æ‰¾é™„è¿‘ä¼‘æ¯ç«™
                nearby_rest_areas = self.find_nearby_rest_areas(highway_code, mileage_num)
                if nearby_rest_areas:
                    desc += f"\n\nğŸ¨ é™„è¿‘ä¼‘æ¯ç«™ï¼š"
                    for area in nearby_rest_areas[:3]:  # æœ€å¤šé¡¯ç¤º3å€‹æœ€è¿‘çš„
                        direction_desc = "å‰æ–¹" if area['is_ahead'] else "å¾Œæ–¹"
                        desc += f"\nâ€¢ {area['name']}ï¼š{direction_desc}{area['distance_km']:.1f}å…¬é‡Œ"
                        desc += f" (è¨­æ–½ï¼š{', '.join(area['facilities'])})"
                
                # ç‰¹æ®Šè·¯æ®µè­¦ç¤º
                warnings = []
                if pd.notna(row.get('æ›²ç‡åŠå¾‘')) and float(row['æ›²ç‡åŠå¾‘']) < 500:
                    warnings.append("æ³¨æ„æ€¥å½ï¼Œå»ºè­°æ¸›é€Ÿæ…¢è¡Œ")
                if pd.notna(row.get('ç¸±å‘å¡åº¦')) and abs(float(row['ç¸±å‘å¡åº¦'])) > 0.05:
                    warnings.append("æ³¨æ„å¡åº¦è®ŠåŒ–ï¼Œä¿æŒå®‰å…¨è»Šè·")
                if row.get('é¿è»Šå½') != 'ç„¡':
                    warnings.append("è·¯æ®µè¨­æœ‰é¿è»Šå½ï¼Œæ³¨æ„å®‰å…¨")
                
                if warnings:
                    desc += f"\n\nâš ï¸ é§•é§›æé†’ï¼š\nâ€¢ " + "\nâ€¢ ".join(warnings)
                
                # é§•é§›å»ºè­°
                desc += f"\n\nğŸ’¡ é§•é§›å»ºè­°ï¼š"
                desc += f"\nâ€¢ å»ºè­°è»Šé€Ÿï¼šä¾è·¯æ³èª¿æ•´ï¼Œæ³¨æ„é€Ÿé™æ¨™ç¤º"
                desc += f"\nâ€¢ è»Šé“é¸æ“‡ï¼šå»ºè­°ä½¿ç”¨ä¸­é–“è»Šé“è¡Œé§›"
                if aux_lanes:
                    desc += f"\nâ€¢ åŒ¯å…¥åŒ¯å‡ºï¼šæ³¨æ„è¼”åŠ©è»Šé“è»Šè¼›å‹•æ…‹"
                
                descriptions.append(desc.strip())
                
            except Exception as e:
                logger.warning(f"ç”Ÿæˆè·¯æ®µ {idx} çš„å¢å¼·æè¿°å¤±æ•—: {e}")
                # ä½¿ç”¨åŸºæœ¬æè¿°ä½œç‚ºå‚™ç”¨
                basic_desc = f"è·¯æ®µè³‡è¨Šï¼š{row.get('åœ‹é“ç·¨è™Ÿæ–¹å‘', '')} {row.get('æ¨è™Ÿ', '')} - åŸºæœ¬é“è·¯è³‡æ–™"
                descriptions.append(basic_desc)
        
        logger.info(f"ç”Ÿæˆå¢å¼·æ–‡å­—æè¿°: {len(descriptions)} å€‹")
        return descriptions
    
    def process_all_data_enhanced(self) -> List[Dict[str, Any]]:
        """è™•ç†æ‰€æœ‰è³‡æ–™ä¸¦ç”Ÿæˆå¢å¼·çš„è¨“ç·´æ ¼å¼"""
        # è¼‰å…¥è³‡æ–™
        highway1_df, highway3_df = self.load_highway_data()
        
        # æ¸…ç†è³‡æ–™
        highway1_clean = self.clean_and_normalize_data(highway1_df)
        highway3_clean = self.clean_and_normalize_data(highway3_df)
        
        # ç”Ÿæˆå¢å¼·çš„æ–‡å­—æè¿°
        highway1_texts = self.generate_enhanced_text_descriptions(highway1_clean)
        highway3_texts = self.generate_enhanced_text_descriptions(highway3_clean)
        
        # åˆä½µæ‰€æœ‰æ–‡æœ¬
        all_texts = highway1_texts + highway3_texts
        
        # åˆ†å‰²æ–‡æœ¬ä¸¦æ·»åŠ å…ƒæ•¸æ“š
        processed_data = []
        for i, text in enumerate(all_texts):
            chunks = self.chunk_text(text)
            
            # ç¢ºå®šä¾†æºå’ŒåŸºæœ¬è³‡è¨Š
            source = 'highway1' if i < len(highway1_texts) else 'highway3'
            
            # å¾åŸå§‹è³‡æ–™ç²å–ä½ç½®è³‡è¨Š
            if source == 'highway1':
                row = highway1_clean.iloc[i]
            else:
                row = highway3_clean.iloc[i - len(highway1_texts)]
            
            # è§£æä½ç½®è³‡è¨Š
            direction_code = str(row['åœ‹é“ç·¨è™Ÿæ–¹å‘'])
            mileage_num = float(row['é‡Œç¨‹']) / 1000
            
            for j, chunk in enumerate(chunks):
                processed_data.append({
                    'id': f'{source}_{i}_{j}',
                    'text': chunk,
                    'source': source,
                    'chunk_index': j,
                    'original_index': i,
                    'highway': 'åœ‹é“1è™Ÿ' if 'N0010' in direction_code else 'åœ‹é“3è™Ÿ',
                    'direction': 'åŒ—å‘' if 'NB' in direction_code else 'å—å‘',
                    'mileage': mileage_num,
                    'station_code': f"{row['åœ‹é“ç·¨è™Ÿæ–¹å‘']},{row['æ¨è™Ÿ']}",
                    'friendly_location': self.resolve_station_code(f"{row['åœ‹é“ç·¨è™Ÿæ–¹å‘']},{row['æ¨è™Ÿ']}"),
                    'coordinates': {
                        'lat': float(row['ç¶“ç·¯åº¦åæ¨™Lat']) if pd.notna(row['ç¶“ç·¯åº¦åæ¨™Lat']) else None,
                        'lng': float(row['ç¶“ç·¯åº¦åæ¨™Lon']) if pd.notna(row['ç¶“ç·¯åº¦åæ¨™Lon']) else None
                    }
                })
        
        logger.info(f"å¢å¼·è™•ç†å®Œæˆï¼Œç¸½å…±ç”Ÿæˆ {len(processed_data)} å€‹æ–‡æœ¬å¡Š")
        
        # çµ±è¨ˆå¢å¼·è³‡æ–™
        highway_stats = {}
        for item in processed_data:
            highway = item['highway']
            highway_stats[highway] = highway_stats.get(highway, 0) + 1
        
        logger.info(f"å¢å¼·è³‡æ–™åˆ†å¸ƒ: {highway_stats}")
        
        return processed_data

def main():
    """æ¸¬è©¦å¢å¼·è™•ç†å™¨"""
    try:
        processor = EnhancedHighwayCSVProcessor()
        processed_data = processor.process_all_data_enhanced()
        
        # å„²å­˜å¢å¼·è³‡æ–™
        output_file = "enhanced_highway_data.json"
        output_path = processor.save_processed_data(processed_data, output_file)
        
        print(f"å¢å¼·è™•ç†å®Œæˆï¼ç”Ÿæˆäº† {len(processed_data)} å€‹æ–‡æœ¬å¡Š")
        print(f"è¼¸å‡ºæª”æ¡ˆï¼š{output_path}")
        
        # é¡¯ç¤ºç¯„ä¾‹
        print("\n=== ç¯„ä¾‹å¢å¼·æè¿° ===")
        for i in range(min(2, len(processed_data))):
            print(f"\n--- å¡Š {i+1} ---")
            print(f"ä½ç½®ï¼š{processed_data[i]['friendly_location']}")
            print(f"æ–‡æœ¬é è¦½ï¼š{processed_data[i]['text'][:300]}...")
            
        return processed_data
        
    except Exception as e:
        logger.error(f"å¢å¼·è™•ç†å¤±æ•—: {e}")
        return None

if __name__ == "__main__":
    main()